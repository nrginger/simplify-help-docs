{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ace5e9-1cf9-4a31-9740-24ca2f412512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ace_tools\n",
      "  Downloading ace_tools-0.0-py3-none-any.whl.metadata (300 bytes)\n",
      "Downloading ace_tools-0.0-py3-none-any.whl (1.1 kB)\n",
      "Installing collected packages: ace_tools\n",
      "Successfully installed ace_tools-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d46b7f7-aa71-474d-8079-e31e622c8f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.12/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем библиотеку для красивого вывода (если ещё не установлено)\n",
    "!pip install tabulate\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf39d5b7-2189-481a-a9ab-6df3ecafe129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Загружаем JSON-файл\n",
    "with open('combined_sample50_judge.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3b788e7-4614-4230-8464-e1b5ea6adc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Преобразуем в DataFrame\n",
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d72bea9-6fe5-4632-a797-f6d800528808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         model  clarity  direct_address  bureaucratic_words  structure  \\\n",
      "0  deepseek-v3      5.0            2.78                 5.0       4.84   \n",
      "1        llama      NaN             NaN                 NaN        NaN   \n",
      "2      mistral      NaN             NaN                 NaN        NaN   \n",
      "3         qwen      NaN             NaN                 NaN        NaN   \n",
      "\n",
      "   brevity  overall  \n",
      "0     4.98     22.6  \n",
      "1      NaN      NaN  \n",
      "2      NaN      NaN  \n",
      "3      NaN      NaN  \n",
      "+-------------+-----------+------------------+----------------------+-------------+-----------+-----------+\n",
      "| model       |   clarity |   direct_address |   bureaucratic_words |   structure |   brevity |   overall |\n",
      "+=============+===========+==================+======================+=============+===========+===========+\n",
      "| deepseek-v3 |      5.00 |             2.78 |                 5.00 |        4.84 |      4.98 |     22.60 |\n",
      "+-------------+-----------+------------------+----------------------+-------------+-----------+-----------+\n",
      "| llama       |    nan    |           nan    |               nan    |      nan    |    nan    |    nan    |\n",
      "+-------------+-----------+------------------+----------------------+-------------+-----------+-----------+\n",
      "| mistral     |    nan    |           nan    |               nan    |      nan    |    nan    |    nan    |\n",
      "+-------------+-----------+------------------+----------------------+-------------+-----------+-----------+\n",
      "| qwen        |    nan    |           nan    |               nan    |      nan    |    nan    |    nan    |\n",
      "+-------------+-----------+------------------+----------------------+-------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "criteria = ['clarity', 'direct_address', 'bureaucratic_words', 'structure', 'brevity']\n",
    "\n",
    "# Правильный способ получить список моделей\n",
    "models = sorted({col.split('_', 1)[0] for col in df.columns if '_' in col})\n",
    "\n",
    "rows = []\n",
    "for m in models:\n",
    "    row = {'model': m}\n",
    "    for crit in criteria:\n",
    "        col = f\"{m}_{crit}\"\n",
    "        if col in df.columns:\n",
    "            row[crit] = df[col].mean()\n",
    "        else:\n",
    "            row[crit] = float('nan')\n",
    "    row['overall'] = sum(v for v in row.values() if isinstance(v, (int, float)))\n",
    "    rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values('overall', ascending=False)\n",
    "print(summary_df)\n",
    "\n",
    "# 5. Выводим в консоль красиво\n",
    "print(tabulate(summary_df, headers='keys', tablefmt='grid', floatfmt=\".2f\", showindex=False))\n",
    "\n",
    "# 6. Сохраняем результат\n",
    "summary_df.to_csv('judge_stats_summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74764dfb-dea5-4468-8461-422f140954de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama_finetuned_clarity', 'llama_finetuned_direct_address', 'llama_finetuned_bureaucratic_words', 'llama_finetuned_structure', 'llama_finetuned_brevity', 'mistral_instruct_clarity', 'mistral_instruct_direct_address', 'mistral_instruct_bureaucratic_words', 'mistral_instruct_structure', 'mistral_instruct_brevity', 'qwen_finetuned_clarity', 'qwen_finetuned_direct_address', 'qwen_finetuned_bureaucratic_words', 'qwen_finetuned_structure', 'qwen_finetuned_brevity', 'deepseek-v3_clarity', 'deepseek-v3_direct_address', 'deepseek-v3_bureaucratic_words', 'deepseek-v3_structure', 'deepseek-v3_brevity']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71ed0b3a-1526-49a8-be39-38083f6c61c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deepseek-v3', 'deepseek-v3_bureaucratic', 'deepseek-v3_direct', 'llama_finetuned', 'llama_finetuned_bureaucratic', 'llama_finetuned_direct', 'mistral_instruct', 'mistral_instruct_bureaucratic', 'mistral_instruct_direct', 'qwen_finetuned', 'qwen_finetuned_bureaucratic', 'qwen_finetuned_direct']\n",
      "['clarity', 'direct_address', 'bureaucratic_words', 'structure', 'brevity']\n",
      "['llama_finetuned_clarity', 'llama_finetuned_direct_address', 'llama_finetuned_bureaucratic_words', 'llama_finetuned_structure', 'llama_finetuned_brevity', 'mistral_instruct_clarity', 'mistral_instruct_direct_address', 'mistral_instruct_bureaucratic_words', 'mistral_instruct_structure', 'mistral_instruct_brevity', 'qwen_finetuned_clarity', 'qwen_finetuned_direct_address', 'qwen_finetuned_bureaucratic_words', 'qwen_finetuned_structure', 'qwen_finetuned_brevity', 'deepseek-v3_clarity', 'deepseek-v3_direct_address', 'deepseek-v3_bureaucratic_words', 'deepseek-v3_structure', 'deepseek-v3_brevity']\n"
     ]
    }
   ],
   "source": [
    "print(models)     # ['deepseek-v3', …]\n",
    "print(criteria)   # ['clarity', 'direct_address', 'bureaucratic_words', …]\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65995796-b773-4158-b182-ea66457cbd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>clarity</th>\n",
       "      <th>direct_address</th>\n",
       "      <th>bureaucratic_words</th>\n",
       "      <th>structure</th>\n",
       "      <th>brevity</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.78</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.98</td>\n",
       "      <td>22.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen_finetuned</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.48</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.34</td>\n",
       "      <td>3.80</td>\n",
       "      <td>20.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral_instruct</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.64</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.58</td>\n",
       "      <td>16.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama_finetuned</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.24</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  clarity  direct_address  bureaucratic_words  structure  \\\n",
       "3       deepseek-v3     5.00            2.78                5.00       4.84   \n",
       "2    qwen_finetuned     4.22            3.48                4.20       4.34   \n",
       "1  mistral_instruct     3.44            2.64                3.26       3.52   \n",
       "0   llama_finetuned     3.14            2.38                3.38       2.86   \n",
       "\n",
       "   brevity  overall  \n",
       "3     4.98    22.60  \n",
       "2     3.80    20.04  \n",
       "1     3.58    16.44  \n",
       "0     3.24    15.00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Загружаем JSON-файл\n",
    "with open('combined_sample50_judge.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Преобразуем в DataFrame\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "# 3. Явно задаём список моделей и критериев\n",
    "models = [\n",
    "    'llama_finetuned',\n",
    "    'mistral_instruct',\n",
    "    'qwen_finetuned',\n",
    "    'deepseek-v3'\n",
    "]\n",
    "criteria = [\n",
    "    'clarity',\n",
    "    'direct_address',\n",
    "    'bureaucratic_words',\n",
    "    'structure',\n",
    "    'brevity'\n",
    "]\n",
    "\n",
    "# 4. Считаем средний балл по критериям и общий балл\n",
    "rows = []\n",
    "for m in models:\n",
    "    row = {'model': m}\n",
    "    for crit in criteria:\n",
    "        col_name = f\"{m}_{crit}\"\n",
    "        # Проверяем, что такая колонка есть\n",
    "        if col_name in df.columns:\n",
    "            row[crit] = df[col_name].mean()\n",
    "        else:\n",
    "            row[crit] = float('nan')\n",
    "    # Общий балл\n",
    "    row['overall'] = sum(row[crit] for crit in criteria if pd.notna(row[crit]))\n",
    "    rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values('overall', ascending=False)\n",
    "\n",
    "# 5. Сохраняем и выводим результат\n",
    "summary_df.to_csv('judge_stats_summary_explicit.csv', index=False)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afc37222-661c-4721-901c-3af29dba0dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объединённый файл сохранён как combined_sample50_judge_merged.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Читаем оба JSON-файла\n",
    "with open('combined_sample50_judge_1.json', 'r', encoding='utf-8') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open('combined_sample50_judge_round2.json', 'r', encoding='utf-8') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# 2. Объединяем списки записей\n",
    "#    Предполагается, что оба файла содержат JSON-массивы (lists)\n",
    "combined = data1 + data2\n",
    "\n",
    "# 3. Сохраняем в новый файл\n",
    "with open('combined_sample50_judge_merged.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Объединённый файл сохранён как combined_sample50_judge_merged.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93300330-337b-4636-8ccb-460de213557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>clarity</th>\n",
       "      <th>direct_address</th>\n",
       "      <th>bureaucratic_words</th>\n",
       "      <th>structure</th>\n",
       "      <th>brevity</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>2.95</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.99</td>\n",
       "      <td>22.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen_finetuned</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.58</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.88</td>\n",
       "      <td>20.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral_instruct</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.51</td>\n",
       "      <td>3.56</td>\n",
       "      <td>16.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama_finetuned</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.53</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  clarity  direct_address  bureaucratic_words  structure  \\\n",
       "3       deepseek-v3     4.99            2.95                4.98       4.83   \n",
       "2    qwen_finetuned     4.15            3.58                4.18       4.36   \n",
       "1  mistral_instruct     3.45            2.69                3.28       3.51   \n",
       "0   llama_finetuned     3.10            2.53                3.31       2.93   \n",
       "\n",
       "   brevity  overall  \n",
       "3     4.99    22.74  \n",
       "2     3.88    20.15  \n",
       "1     3.56    16.49  \n",
       "0     3.23    15.10  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Загружаем JSON-файл\n",
    "with open('combined_sample50_judge_merged.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Преобразуем в DataFrame\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "# 3. Явно задаём список моделей и критериев\n",
    "models = [\n",
    "    'llama_finetuned',\n",
    "    'mistral_instruct',\n",
    "    'qwen_finetuned',\n",
    "    'deepseek-v3'\n",
    "]\n",
    "criteria = [\n",
    "    'clarity',\n",
    "    'direct_address',\n",
    "    'bureaucratic_words',\n",
    "    'structure',\n",
    "    'brevity'\n",
    "]\n",
    "\n",
    "# 4. Считаем средний балл по критериям и общий балл\n",
    "rows = []\n",
    "for m in models:\n",
    "    row = {'model': m}\n",
    "    for crit in criteria:\n",
    "        col_name = f\"{m}_{crit}\"\n",
    "        # Проверяем, что такая колонка есть\n",
    "        if col_name in df.columns:\n",
    "            row[crit] = df[col_name].mean()\n",
    "        else:\n",
    "            row[crit] = float('nan')\n",
    "    # Общий балл\n",
    "    row['overall'] = sum(row[crit] for crit in criteria if pd.notna(row[crit]))\n",
    "    rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values('overall', ascending=False)\n",
    "\n",
    "# 5. Сохраняем и выводим результат\n",
    "summary_df.to_csv('judge_stats_summary_explicit.csv', index=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899259bd-f1ff-40e3-bc64-85b3925390a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
