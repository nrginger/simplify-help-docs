{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd4176-012f-4e77-bc85-d36a39870ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fine-tune **ruGPT-3-small** (≈ 1.3 B, GPT-2-style) с LoRA\n",
    "на MacBook (Apple M-series, 16 GB unified memory, MPS).\n",
    "\n",
    "— контекст 1024 токенов;\n",
    "— без bitsandbytes (MPS его не поддерживает);\n",
    "— минимальный batch (1) + градиент-аккумуляция, чтобы не вылетать по памяти.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb25d9f1-6e68-43b6-9eac-649a88d2a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, torch\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\"   # <- глушим fp16/bf16\n",
    "gc.collect(); torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d318811-b520-40cb-b3d6-cf9e7ee9800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: peft in /opt/anaconda3/lib/python3.12/site-packages (0.15.2)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. УСТАНОВКА\n",
    "# ============================================================\n",
    "# Внутри venv / conda с PyTorch ≥ 2.2 и поддержкой mps_device.\n",
    "!pip install -U transformers datasets peft accelerate evaluate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1deb982f-6846-4953-9b5a-8477c8c3a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. ЧТЕНИЕ КОРПУСА (CSV/TSV/JSONL) → src/tgt\n",
    "# ============================================================\n",
    "import pandas as pd, numpy as np, torch, textwrap, random, os\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_FILE = \"finetuning_text_pairs_3_clean_v2.csv\"\n",
    "FILE_TYPE = \"csv\"          # csv | tsv | jsonl\n",
    "COL_SRC   = \"finetuning_text_pairs_3\"\n",
    "COL_TGT   = \"Unnamed: 1\"\n",
    "VAL_SPLIT = 0.1\n",
    "SEED      = 42\n",
    "\n",
    "if FILE_TYPE == \"tsv\":\n",
    "    df = pd.read_csv(DATA_FILE, sep=\"\\t\")\n",
    "elif FILE_TYPE == \"csv\":\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "elif FILE_TYPE == \"jsonl\":\n",
    "    df = pd.read_json(DATA_FILE, lines=True)\n",
    "else:\n",
    "    raise ValueError(\"unknown FILE_TYPE\")\n",
    "\n",
    "df = df.dropna(subset=[COL_SRC, COL_TGT]).rename(\n",
    "    columns={COL_SRC: \"src\", COL_TGT: \"tgt\"}\n",
    ")\n",
    "COL_SRC = \"src\"; COL_TGT = \"tgt\"\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=VAL_SPLIT, random_state=SEED)\n",
    "train_ds, val_ds = map(Dataset.from_pandas, (train_df, val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76d87fa-9e71-4039-8a03-2e620d3b9cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 126,042,624 || trainable%: 0.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2. МОДЕЛЬ + LoRA (без квантов, всё fp16 на MPS)\n",
    "# ============================================================\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "MODEL_ID = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "tok.pad_token = tok.eos_token        # GPT-2 нет pad, используем eos\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "base_model.to(device)\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8, lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],  # основные линейные в GPT-2-блоке\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(base_model, lora_cfg)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f63b06f-c14a-43c5-910a-cc3f9790f70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7739443632734e28b523edabb77d0c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2499 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c35917bc6545db86dd0e12d7086488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3. ТОКЕНИЗАЦИЯ (контекст 1024, -100 на prompt)\n",
    "# ============================================================\n",
    "MAXLEN  = 1024\n",
    "PROMPT  = \"Упрости текст, сохраняя смысл:\\n\\n{src}\\n\\nУпрощённая версия:\"\n",
    "\n",
    "def tokenize(batch):\n",
    "    input_ids, labels, attention = [], [], []\n",
    "    for src, tgt in zip(batch[COL_SRC], batch[COL_TGT]):\n",
    "        prompt_ids  = tok(PROMPT.format(src=src), add_special_tokens=False).input_ids\n",
    "        target_ids  = tok(tgt, add_special_tokens=False).input_ids + [tok.eos_token_id]\n",
    "        ids   = (prompt_ids + target_ids)[:MAXLEN]\n",
    "        label = ([-100]*len(prompt_ids) + target_ids)[:MAXLEN]\n",
    "        input_ids.append(ids)\n",
    "        labels.append(label)\n",
    "        attention.append([1]*len(ids))\n",
    "    return {\"input_ids\":input_ids, \"labels\":labels, \"attention_mask\":attention}\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True, remove_columns=train_ds.column_names)\n",
    "val_ds   = val_ds.map(tokenize, batched=True, remove_columns=val_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29c4570c-8e9b-4c89-b315-84d3d2c7510b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 4:05:20, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.755500</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.586400</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.522400</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.453400</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.424100</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.417200</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.386200</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('rugpt3_lora_adapter/tokenizer_config.json',\n",
       " 'rugpt3_lora_adapter/special_tokens_map.json',\n",
       " 'rugpt3_lora_adapter/vocab.json',\n",
       " 'rugpt3_lora_adapter/merges.txt',\n",
       " 'rugpt3_lora_adapter/added_tokens.json',\n",
       " 'rugpt3_lora_adapter/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. ТРЕНИРОВКА (batch 1, GA 32 → effective BS 32)\n",
    "# ============================================================\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"rugpt3_lora\",\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=2e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    fp16=False,     # ← выключаем\n",
    "    bf16=False,     # ← и это тоже\n",
    "    dataloader_pin_memory=False,   # MPS не любит pin_memory\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(\n",
    "    tok,\n",
    "    model=model,\n",
    "    pad_to_multiple_of=8,   # аккуратный padding\n",
    "    label_pad_token_id=-100\n",
    ")\n",
    "trainer  = Trainer(model=model, args=args,\n",
    "                   train_dataset=train_ds, eval_dataset=val_ds,\n",
    "                   data_collator=collator)\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"rugpt3_lora_adapter\")\n",
    "tok.save_pretrained(\"rugpt3_lora_adapter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119b4903-6af5-4f06-b44e-fc3ff01c1361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(34381) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (2.2.0)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (4.66.5)\n",
      "Building wheels for collected packages: rouge_score\n",
      "\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=cb05602d865717c78b94c170a08b79cc8ee840812be03d85c60b66a1ec57a33a\n",
      "  Stored in directory: /Users/aleksandraskorodumova/Library/Caches/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f45cb46d-1833-4f76-bdf4-c56224d33b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(34407) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (2024.9.11)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (5.2.1)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [sacrebleu]\n",
      "\u001b[1A\u001b[2KSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1141083d-e0b4-470f-a35d-7a754f5628c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- #1\n",
      "SRC: Антивирусное программное обеспечение способно обнаружить и уничтожить большинство [...]\n",
      "REF: Для защиты от вредоносных программ на вашем компьютере предустановлен антивирус [...]\n",
      "PRD: ### Антивирусное программное обеспечение: как защитить от вирусов #### Инструкция по [...]\n",
      "\n",
      "--- #2\n",
      "SRC: НАСТРОЙКИ ДЛЯ ОТДЕЛЬНОГО ПРИЛОЖЕНИЯ Можно настроить инструменты для использования в [...]\n",
      "REF: Настройки для отдельного приложения Вы можете настроить инструменты для конкретного [...]\n",
      "PRD: ### Установка инструментов для работы с приложениями #### Как настроить инструмент [...]\n",
      "\n",
      "--- #3\n",
      "SRC: Масса нетто кг 34 3. ПОДГОТОВКА К ЭКСПЛУАТАЦИИ СТАНКА. Если станок внесен в зимнее [...]\n",
      "REF: ### Подготовка к эксплуатации станка **Масса нетто:** 34 кг #### Если станок занесли [...]\n",
      "PRD: ### Подготовка к установке станка 1. **Подготовка к установке** 1. **Установка** 2. [...]\n",
      "\n",
      "--- #4\n",
      "SRC: Макро Менеджер 15 Проверим функцию в игре: В реальных шутерах FPS, отдача оружия [...]\n",
      "REF: Макро Менеджер 15: Проверка функции в игре. В современных FPS-шутерах отдача оружия [...]\n",
      "PRD: ### Как повысить точность стрельбы #### Как уменьшить отдачу #### Как уменьшить [...]\n",
      "\n",
      "--- #5\n",
      "SRC: Тыльная панель 11. Слот замка для предотвращения кражи ( ) [...]\n",
      "REF: Тыльная панель: 11. Слот замка для предотвращения кражи. Подробнее: [...]\n",
      "PRD: **Как подключить гитару:** 1. Подключите разъем INPUT к разъему INPUT. 2. Подключите [...]\n",
      "\n",
      "--- #6\n",
      "SRC: \"Исходящие\" Папка \"Исходящие\" напоминает список исходящих вызовов. В ней может [...]\n",
      "REF: ### Папка \"Исходящие\" Папка \"Исходящие\" функционирует аналогично списку исходящих [...]\n",
      "PRD: **\"Исходящие\"** - это список исходящих вызовов. В нем может храниться до 5 [...]\n",
      "\n",
      "--- #7\n",
      "SRC: При использовании настройки высокой мощности содержимое может внезапно выкипеть и [...]\n",
      "REF: Использование функции высокой мощности может привести к внезапному выкипанию [...]\n",
      "PRD: При использовании настройки высокой мощности содержимое может внезапно выкипеть и [...]\n",
      "\n",
      "--- #8\n",
      "SRC: Закупорены отверстия крыльчатки. >>> Отверстия нижней и верхней крыльчатки могут [...]\n",
      "REF: Отверстия крыльчатки засорены. Возможно, отверстия нижней и верхней крыльчатки [...]\n",
      "PRD: Закупорены отверстия крыльчатки. ***Отверстия нижней и верхней крыльчатки могут быть [...]\n",
      "\n",
      "--- #9\n",
      "SRC: Y Избегайте нечаянных запусков двигателя. Убедитесь, что двигатель заглушен перед [...]\n",
      "REF: Техника безопасности при эксплуатации: Предотвращение случайного запуска: - Перед [...]\n",
      "PRD: ### Как избежать проблем с бензином 1. Проверьте, что двигатель заглушен перед любой [...]\n",
      "\n",
      "--- #10\n",
      "SRC: РУКОВОДСТВО ПО ЭКСПЛУАТАЦИИ КУХОННЫХ ВЫТЯЖЕК 4.1* Вытяжку допускается включать [...]\n",
      "REF: Правила безопасного использования кухонной вытяжки: • Подключайте устройство только [...]\n",
      "PRD: ### Как правильно готовить вытяжку #### Как правильно готовить вытяжку 1. [...]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (src, ref, pr) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sample[COL_SRC], sample[COL_TGT], preds), \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSRC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtextwrap\u001b[38;5;241m.\u001b[39mshorten(src,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m90\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mREF: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtextwrap\u001b[38;5;241m.\u001b[39mshorten(ref,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m90\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPRD: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtextwrap\u001b[38;5;241m.\u001b[39mshorten(pr,\u001b[38;5;250m  \u001b[39m\u001b[38;5;241m90\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mROUGE-L:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rouge\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39msample[COL_TGT])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrougeL\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchrF:\u001b[39m\u001b[38;5;124m\"\u001b[39m,     chrf\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39msample[COL_TGT]))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/evaluate/module.py:455\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_batch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/evaluate/module.py:514\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m batch \u001b[38;5;241m=\u001b[39m {input_name: batch[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_feature_from_batch(batch)\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_writer()\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/evaluate/module.py:595\u001b[0m, in \u001b[0;36mEvaluationModule._infer_feature_from_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m([(k, v[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_feature_from_example(example)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5. БЫСТРАЯ ПРОВЕРКА (ROUGE-L + chrF)\n",
    "# ============================================================\n",
    "import evaluate, textwrap\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "chrf  = evaluate.load(\"chrf\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def simplify(text, temp=0.3, top_p=0.9, max_new=256):\n",
    "    prompt = PROMPT.format(src=text)\n",
    "    ids = tok(prompt, return_tensors=\"pt\").to(device)\n",
    "    out = model.generate(**ids, do_sample=True, temperature=temp,\n",
    "                         top_p=top_p, max_new_tokens=max_new,\n",
    "                         eos_token_id=tok.eos_token_id)\n",
    "    return tok.decode(out[0], skip_special_tokens=True)\\\n",
    "             .split(\"Упрощённая версия:\")[-1].strip()\n",
    "\n",
    "sample = val_df.sample(10, random_state=SEED)\n",
    "preds  = [simplify(t) for t in sample[COL_SRC]]\n",
    "\n",
    "for i, (src, ref, pr) in enumerate(zip(sample[COL_SRC], sample[COL_TGT], preds), 1):\n",
    "    print(f\"\\n--- #{i}\\nSRC: {textwrap.shorten(src, 90)}\"\n",
    "          f\"\\nREF: {textwrap.shorten(ref, 90)}\"\n",
    "          f\"\\nPRD: {textwrap.shorten(pr,  90)}\")\n",
    "\n",
    "print(\"\\nROUGE-L:\", rouge.compute(predictions=preds, references=sample[COL_TGT])[\"rougeL\"])\n",
    "print(\"chrF:\",     chrf.compute(predictions=preds, references=sample[COL_TGT]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fabf0-e9ca-4eef-a33a-1112cd9ecee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
